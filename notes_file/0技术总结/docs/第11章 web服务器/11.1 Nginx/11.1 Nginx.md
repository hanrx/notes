
# 1、基本概念

## 1.1、nginx是什么
Nginx(engine x)是一个高性能的HTTP和反向代理服务器，特点是占有内存少，并发能力强，事实上nginx的并发能力确实在同类型的网页服务器中表现较好。

Nginx可以作为静态页面的web服务器，同时还支持cGI协议的动态语言，比如perl、php等。但是不支持java。Java程序只能通过与tomcat配合完成。Nginx专为性能
优化而开发，性能是其最重用的考量，实现上非常注重效率，能经受高负载的考验，有报告表明能支持高达50，000个并发连接数。
https://lnmp.org/nginx.html

## 1.2、反向代理
* 正向代理：在客户端（浏览器）配置代理服务器，通过代理服务器进行互联网访问
  > Nginx不仅可以做反向代理，实现负载均衡。还能用作正向代理来进行上网等功能。
  > 正向代理：如果把局域网外的Internet想象成一个巨大的资源库，则局域网中的客户端想要访问Internet，则需要通过代理服务器来访问，这种代理服务就称为正向代理。
  > ![img.png](img.png)
  > ![img_1.png](img_1.png)
* 反向代理：
  > 反向代理，其实客户端对代理是无感知的，因为客户端不需要任何配置就可以访问，我们只需要请求发送到方向代理服务器，由反向代理服务器去选择目标服务器获取数据后，
  > 再返回给客户端，此时反向代理服务器和目标服务器对外就是一个服务器，暴露的是代理服务器地址，隐藏了真实服务器IP地址。
  > ![img_3.png](img_3.png)

## 1.3、负载均衡
客户端发送多个请求到服务器，服务器处理请求，有一些可能要与数据库进行交互，服务器处理完毕后，再将结果返回给客户端。

这种架构模式对于早期的系统相对单一，并发请求相对较少的情况下是比较适合的，成本也低。但是随着信息数量的不断增长，访问量和数据量的飞速增长，以及系统业务
的复杂度增加，这种架构会造成服务器相对应客户端的请求日益缓慢，并发量特别大的时候，还容易造成服务器直接崩溃。很明显这是由于服务器性能的瓶颈造成的问题，那么如何解决这种情况呢？
 
单个服务器解决不了，我们增加服务器的数量，然后将请求分发到各个服务器上，将原先请求集中到单个服务器上的情况改为将请求分发到多个服务器上，将负载分发到不同
的服务器，也就是我们所说的负载均衡。
![img_4.png](img_4.png)

## 1.4、动静分离
为加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度。降低原来单个服务器的压力。
![img_5.png](img_5.png)
![img_6.png](img_6.png)

# 2、nginx安装、常用命令和配置文件

## 2.1、在linux系统中安装nginx
* 1、使用远程连接工具连接linux操作系统。![img_7.png](img_7.png)
* 2、nginx需要的依赖：pcre-8.37.tar.gz、openssl-1.0.1t.tar.gz、zlib-1.2.8.tar.gz、
  * 第一步，安装pcre：wget http://downloads.sourceforge.net/project/pcre/pcre/8.37/pcre-8.37.tar.gz
    解压文件：。./configure完成后，回到pcre目录下执行make，再执行make install
    ![img_9.png](img_9.png)
  * 第二步，安装openssl
  * 第三步，安装zlib。
  
  * 第二种方式：yum -y install make zlib zlib-devel gcc-c++libtool openssl openssl-devel。![img_8.png](img_8.png)
* 3、安装nginx
  * 解压缩nginx-xx.tar.gz包。
    ![img_10.png](img_10.png)
  * 进入解压缩目录，执行./configure。 (检查)
    ![img_11.png](img_11.png)
  * make&&make install。（编译/编译安装）
    ![img_12.png](img_12.png)
  安装成功之后，在/usr下多出来一个文件夹local/nginx，在nginx有sbin有启动脚本。
* 4、端口设置，开发nginx端口。
  * 查看开放的端口号：firewall-cmd --list-all
  * 设置开放的端口号：firewall-cmd --and-service=http --permanent    
    ![img_13.png](img_13.png)
  * 重启防火墙：firewall-cmd--reload


## 2.2、nginx常用命令
* 1、使用nginx操作命令前提条件：必须进入nginx的目录：/usr/local/nginx/sbin
* 2、查看nginx的版本号
  > ./nginx -v
  > ![img_14.png](img_14.png)
* 3、启动nginx
  > ./nginx
  > ![img_16.png](img_16.png)
* 4、关闭nginx
  > ./nginx -s stop
  > ![img_15.png](img_15.png)  
* 5、重新加载nginx
  > ./nginx -s reload
  > ![img_17.png](img_17.png)

## 2.3、nginx配置文件
* 1、nginx配置文件位置:
  > /usr/local/nginx/conf/nginx.conf
  > ![img_18.png](img_18.png)
* 2、nginx配置文件组成：
  > 1、nginx配置文件有三部分组成。
  > * 第一部分：全局块
  >   从配置文件开始到events块之间的内容，主要会设置一些影响nginx服务器整体运行的配置指令，主要包括配置运行Nginx服务器的用户（组）、允许生成的
  >   worker process数，进程PID存放路径、日志存放路径和类型以及配置文件的引入等。
  >   
  >   比如第一行的配置：
  >   ![img_19.png](img_19.png)
  >   这是Nginx服务器并发处理服务的关键配置，worker_processes值越大，可以支持的并发处理量也越多，但是会受到硬件、软件等设备的制约。
  > * 第二部分：events块
  >   比如上面的配置：
  >   ![img_20.png](img_20.png)
  >   events块涉及的指令主要影响Nginx服务器与用户的网络连接，常用的设置包括是否开启对多work process下网络连接进行序列化，是否允许同时接受多个
  >   网络连接，选取哪些事件驱动模型来处理连接请求，每个word process可以同时支持的最大连接数等。
  >   上述例子就表示每个work process支持的最大连接数为1024.
  >   这部分的配置对Nginx的性能影响较大，在实际中应该灵活配置。
  > 
  > * 第三部分：http块
  >   ![img_21.png](img_21.png)
  >   ![img_22.png](img_22.png)
  >   ![img_23.png](img_23.png)
  >   ![img_24.png](img_24.png)
  >   这算是Nginx服务器配置中最频繁的部分，代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里。
  >   需要注意的是：http块也可以包括http全局块、server块。
  >   * http全局块
  >     http全局块配置的指令包括文件引入、MIME-TYPE定义、日志自定义、连接超时时间、单链接请求数上限等。 
  >   * server块
  >     这块和虚拟主机有密切关系，虚拟主机从用户角度看，和一台独立的硬件主机是完全一样的，该技术的产生是为了节省互联网服务器硬件成本。
  >     每个http块可以包括多个server块，而每个server块就相当于一个虚拟主机。
  >     而每个server块也分为全局server块，以及可以同时包含多个locaton块。
  >     * 全局server块：最常见的配置是本虚拟机主机的监听配置和本虚拟主机的名称或IP配置。
  >     * location块：
  >       一个server块可以配置多个location块。这块的主要作用是基于Nginx服务器接收到的请求字符串（例如server_name/uri-string），对虚拟主机
  >       名称（也可以是IP别名）之外的字符串（例如 前面的/uri-string）进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能，还有
  >       许多第三方模块的配置也在这里进行。

# 3、nginx配置实例 1-反向代理
* 1、实现效果
  >（1）打开浏览器，在浏览器地址栏输入地址www.123.com，跳转到linux系统tomcat主页页面中。
* 2、具体实现
  > * 准备工作：
  >   ![img_25.png](img_25.png)
  > * 访问过程分析
  >   ![img_26.png](img_26.png)
  > * 具体配置：
  >   * 在nginx进行请求转发的配置（反向代理配置）
  >   ![img_27.png](img_27.png)
  > 

2-反向代理
* 1、实现效果：使用nginx反向代理，根据访问的路径跳转到不同的端口的服务中，nginx监听端口为9001。
  ![img_28.png](img_28.png)
* 2、具体实现：
  > ![img_29.png](img_29.png)
  > * 找到nginx配置文件，进行反向代理配置
  >   ![img_30.png](img_30.png)
  >   ![img_31.png](img_31.png)
  > 
* location指令说明：
  > 该指令用于匹配URL。
  > 语法如下：
  > ![img_32.png](img_32.png)
  > * 1、=：用于不含正则表达式的uri前，要求请求字符串与uri严格匹配，如果匹配成功，就停止继续向下搜索并立即处理该请求。
  > * 2、~：用于表示uri包含正则表达式，并且区分大小写。
  > * 3、~*：用于表示uri包含正则表达式，并且不区分大小写。
  > * 4、^~：用于不含正则表达式的uri前，要求Nginx服务器找到标识uri和请求字符串匹配度最高的location后，立即使用此location处理请求，而不再使用
  >   location块中的正则uri和请求字符串做匹配。
  > 注意：如果uri包含正则表达式，则必须有~或者~*标识。

# 4、nginx配置实例 2-负载均衡
1、实现效果：浏览器地址栏输入地址http://192.168.17.129/edu/a.html，负载均衡效果好，平均到8080和8081端口中。
![img_33.png](img_33.png)
3、在nginx的配置文件中进行负载均衡的配置
![img_34.png](img_34.png)

![img_35.png](img_35.png)

在Linux下有Nginx、LVS、Haproxy等等服务可以提供负载均衡服务，而且Nginx提供了几种分配方式（策略）。
* 1、轮询（默认）：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。
* 2、weight：weight代表权重，默认为1，权重越高被分配的客户端越多。指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。例如：
  ![img_36.png](img_36.png)
* 3、ip_hash：每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。例如：
  ![img_37.png](img_37.png)
* 4、fair（第三方）：按后端服务器的响应时间来分配请求，响应时间短的优先分配。
  ![img_38.png](img_38.png)

# 5、nginx配置实例 3-动静分离
![img_39.png](img_39.png)
Nginx动静分离简单来说就是把动态跟静态请求分开，不能理解成只是单纯的把动态页面和静态页面物理分离。严格意义上说应该是动态请求跟静态请求分开，
可以理解成使用Nginx处理静态页面，Tomcat处理动态页面。动静分离从目前实现角度来讲大致分为两种，一种是纯粹把静态文件独立成单独的域名，放在独立的服务器上，
也是目前主流推崇的方案；另外一种做法就是动态跟静态文件混合在一起发布，通过nginx来分开。通过location指定不同的后缀名实现不同的请求转发。通过expires参数设置，
可以使浏览器缓存过期时间，减少与服务器之前的请求和流量。具体Expires定义：是给一个资源设定一个过期时间，也就是说无需去服务端验证，直接通过浏览器自身确认是否过期即可，
所以不会产生额外的流量。此种方法非常适合不经常变动的资源。（如果经常更新的文件，不建议使用Expires来缓存），这里设置3d，表示在这3天之内访问这个URL，发送
一个请求，比对服务器该文件最后更新时间没有变化，则不会从服务器抓取，返回状态码304,如果有修改，则直接从服务器重新下载，返回状态码200。
![img_40.png](img_40.png)

![img_43.png](img_43.png)
* 具体配置：
  ![img_41.png](img_41.png)
  ![img_42.png](img_42.png)
  ![img_44.png](img_44.png)

# 6、nginx配置高可用集群
* 1、什么是nginx高可用
  ![img_45.png](img_45.png)
  * 需要两天nginx服务器
  * 需要keepalived
  * 需要虚拟ip
* 2、配置高可用的准备工作
  ![img_46.png](img_46.png)
  * keepalived安装
    * 安装：yum install keepalived -y ![img_48.png](img_48.png)
    * 检查是否安装:rpm -q -a keepalived ![img_47.png](img_47.png)
    * 安装之后，在/etc里面生成目录keepalived，有文件keepalived.conf（配置文件）。
      ![img_49.png](img_49.png)
* 3、完成高可用配置（主从配置）
  * 修改/etc/keepalived/keepalived.conf配置文件
    ![img_58.png](img_58.png)
    ![img_50.png](img_50.png)
  * 在/usr/local/src添加检测脚本
    ![img_52.png](img_52.png)
  * 把两天服务器上nginx和keepalived启动。
    * 启动nginx：./nginx
    * 启动keepalived：systemctl start keepalived.service
    ![img_53.png](img_53.png)
  * 测试：
    ![img_54.png](img_54.png)
    ![img_55.png](img_55.png)
    
    ![img_56.png](img_56.png)
    ![img_57.png](img_57.png)

# 7、nginx原理
* 1、master 和 worker
  ![img_51.png](img_51.png)

* 2、woeker如何进行工作的
  ![img_59.png](img_59.png)


* 3、一个master多个workers的好处：master-workers的机制的好处
  * 可以使用nginx -s reload热部署。利于nginx进行热部署操作。
  * 每个worker是独立的进程，如果有其中的一个worker出现问题，其他woker独立的，继续进行争抢，实现请求过程，不会造成服务中断。
  > master-workers的机制的好处
  > 
  > 首先，对于每个worker进程来说，独立的进程，不需要加锁，所以省掉了锁带来的开销，同时在编程以及问题查找时，也会方便很多。其次，采用独立的进程，可以让
  > 相互之间不会影响，一个进程退出后，其他进程还在工作，服务不会中断，master进程则很快启动新的worker进程。当然worker进程的异常退出，肯定是程序有
  > bug了，异常退出，会导致当前worker上的所有请求失败，不过不会影响到所有请求，所以降低了风险。
  > 
  > 需要设置多少个worker
  > Nginx同redis类似都采用了io多路复用机制，每个worker都是一个独立的进程，但每个进程里只有一个主线程，通过异步非阻塞的方式来处理请求，即使是千万个
  > 请求也不在话下。每个worker的线程可以把一个cpu的性能发挥到极致。所以worker数和服务器的cpu数相等是最为适宜的。设少了会浪费cpu，设多了会造成cpu频繁
  > 切换上下文带来的损耗。
  > 
  * 设置worker数量。
    * worker_processes 4。work绑定cpu（4work 4cpu）
    * worker_cpu_affinity 0001 0010 0100 1000
  * 连接数 worker_connection
    > 这个值是表示每个worker进程所能建立连接的最大值，所以，一个nginx能建立的最大连接数，应该是worker_connections * worker_processes。当然，
    > 这里说的是最大连接数，对于HTTP请求本地资源来说，能够支持的最大并发数量是worker_connections * worker_processes,如果是支持http1.1的浏览器每次访问
    > 要占两个连接，所以普通的静态访问最大并发数是：worker_connections * worker_processes/2，而如果是HTTP作为反向代理来说，最大并发数量应该是
    > worker_connections * worker_processes /4。因为作为反向代理服务器，每个并发会建立与客户端的连接和与后端服务器的连接，会占用两个连接。




