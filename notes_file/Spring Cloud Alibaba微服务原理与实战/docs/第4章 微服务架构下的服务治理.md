
# [README](../README.md "回到 README")

# 第4章 微服务架构下的服务治理

众所周知，服务与服务之间的远程通信是分布式架构最基本的组成部分，传统意义上的远程通信，更多的时候是解决信息孤岛及数据互联互通问题的，它主要**关注的是数据的共享**。随着SOA生态的不断完善以及微服务架构思想的落地，**服务与服务之间的远程通信需求更多来自于服务的解耦**。同时，业务规模的不断增长会使得微服务数量增加，那么问题也就随之产生了，比如：
* 如何协调线上运行的服务，以及保障服务的高可用性。
* 如何根据不同服务的访问情况来合理地调控服务器资源，提高机器的利用率。
* 线上出现故障时，如何动态地对故障业务做降级、流量控制等。
* 如何动态地更新服务中的配置信息，比如限流阈值、降级开关等。
* 如何实现大规模服务机器所带来的服务地址的管理和服务上下线的动态感知。

为了解决这些问题，就需要一个统一的服务治理框架对服务进行统一、有效的管控，从而保障服务的高效、健康运行，而Dubbo就是一个这样的框架。

**Dubbo是阿里巴巴内部使用的一个分布式服务治理框架**，与2012年开源。由于Dubbo在服务治理这一领域的优势，以及它本身在阿里巴巴经过大规模的业务验证，所以在很短的时间内，Dubbo就被很多互联网公司采用，笔者就是在2013年的时候开始接触Dubbo的，当时在公司内部把Webservice切换到Dubbo框架。

由于某些原因Dubbo在2014年停止了维护，所以那些使用Dubbo框架的公司开始自己维护，比较知名的是当当网开源的DubboX。值得高兴的是，2017年9月，阿里巴巴重启了Dubbo的维护并且做好了长期投入的准备，也对Dubbo的未来做了很多的规划。2018年2月份，Dubbo进入了Apache孵化，这意味着它将不只是阿里巴巴的Dubbo，而是属于开源社区的，也意味着会有更多的开源贡献者参与到Dubbo的开发中来。

2019年5月，Apache Dubbo正式从孵化器中毕业，代表着Apache Dubbo正式成为Apache的顶级项目。笔者在写这本书的时候，Apache Dubbo的最新版本是2.7.5。

本章主要围绕Apcahe Dubbo框架的基本解决方案，以及它背后的一些实现原理和设计思想进行展开，帮助大家更好地了解Apache Dubbo。


## 4.1 如何理解Apache Dubbo

Apache Dubbo是一个分布式服务框架，主要实现多个系统之间的高性能、透明化调用，简单来说它就是一个RPC框架，但是和普通RPC框架不同的是，它提供了服务治理功能，比如服务注册、监控、路由、容错等。
    
促使Apcahe Dubbo框架产生的原因有两个：
* 在大规模服务化之后，服务越来越多，服务消费者在调用服务提供者的服务时，需要在配置文件中维护服务提供者的URL地址，**当服务提供者出现故障或者动态扩容时，所有相关的服务消费者都需要更新本地配置的URL地址，这种维护成本非常高**。这个时候，实现服务的上下动态线感知及服务地址的动态维护就显得非常重要了。
* 随着用户的访问量增大，**后端服务为了支撑更大的访问量，会通过增加服务器来扩容。但是，哪些服务要扩容，哪些服务要缩容，需要一个判断依据，也就是说需要指定每个服务的调用量及响应时间，这个时候，就需要有一种监控手段**，使用监控的数据作为容量规划的参考值，从而实现根据不同服务的访问情况来合理地调控服务器资源，提供机器的利用率。

从如图4-1所示的Apache Dubbo架构图也能够很清晰地看出，除了基本的RPC框架的职能，它的核心功能便是监控及服务注册。
![](images/4.1.1.png)


## 4.2 Apache Dubbo实现远程通信

创建两个普通的Maven工程，分别为order-service和user-service，代表订单服务和用户服务，这两个服务之间在实际业务场景中会存在相互依赖的情况，比如订单服务中的某个功能可能需要查询用户信息时，就需要调用用户服务指定的接口来完成。    user-service的实现流程
* 在user-service服务中定义了两个模块，分别为user-api和user-provider，前者用来定义当前服务对外提供的接口，这个模块会部署到Maven的远程私服上，便于服务调用者依赖；后者是针对这个接口的实现，该实现会独立部署在服务器上。
![](images/4.2.1.png)

* 在user-api中定义一个接口，执行mvn install将其打包成Jar包安装到本地仓库，本地环境的其他项目就可以找到该依赖，当然，如果自己搭建了私服，可以通过mvn deloy发布。
![](images/4.2.2.png)

* 在user-provider中编写实现，这里需要注意的是，user-provider中需要用到user-api中定义的IUserService接口，所以需要先添加user-api的maven dependency依赖。
![](images/4.2.3.png)

* 添加Dubbo的依赖。
![](images/4.2.4.png)

* 创建配置文件resources/META-INF/spring/user-provider.xml，把服务发布到网络上，让其他进程可以访问。因为Dubbo采用了Spring配置的扩展来实现透明的服务发布和服务消费，所以它的配置基本上和以往通过XML形式描述的Bean差不多。
    * dubbo:application用来描述提供方的应用信息，比如应用名称、维护人、版本等，其中应用名称是必填项。开发者或者运维人员可以通过监控平台查看这些信息来更快速地定位和解决问题。
    * dubbo:registry配置注册中心的地址，如果不需要注册中心，可以设置为N/A。Dubbo支持多种注册中心，比如ZooKeeper、Nacos等。
    * dubbo:protocol配置服务提供者的协议信息，Dubbo支持多种协议来发布服务，默认采用Dubbo协议，可选的协议有很多，比如Hessian、Webservice、Thrift等。这意味着如果公司之前采用的协议是Webservice，想切换到Dubbo上来，几乎没有太大的迁移成本。
    * dubbo:service描述需要发布的服务接口，也就是这个接口可供本网络上的其他进程访问。interface表示定义的接口，ref表示这个接口的实现。
![](images/4.2.5.png)

* 加载Spring的XML文件，可以通过ClassPathXmlApplicationContext来完成加载启动的过程，也可以通过Main.main(args)来启动。两者在本质上没有区别，只是Dubbo做了一层封装，简化了开发者的使用。
![](images/4.2.6.png)

* 启动之后，可以在控制台的日志中看到如下信息，说明服务已经发布成功，而且还打印了Dubbo发布的地址dubbo://192.168.13.1:20880/com.gupaoedu.book.dubbo.IUserService，这个地址是一个远程通信地址，服务调用者可以基于该地址来访问该服务完成远程通信的流程。
![](images/4.2.7.png)

order-service的实现流程    
order-service的实现流程比较简单，大部分配置是相同的。
* 添加user-api和Dubbo的Maven依赖，前者是用户访问IUserService接口的方法，后者通过远程代理完成远程通信过程。
![](images/4.2.8.png)

* 在resources/META-INF/spring/consumer.xml中配置远程服务的引用，主要关注一下dubbo：reference这个配置，它会生成一个针对当前interface的远程服务的代理，指向的远程服务地址是user-service发布的Dubbo协议的URL地址。
![](images/4.2.9.png)

* 加载Spring配置文件，使用方式和本地Bean一样，通过从IoC容器中获取一个实例对象进行调用，需要注意的是，这里的IUserService返回的是一个代理对象，它的底层会基于网络通信来实现远程服务的调用。
![](images/4.2.10.png)

上述案例中，演示的仅仅是点对点的通信形式。整体来看，由于Dubbo天然地集成了Spring，并且在此基础上做了标签的扩展，所以整体的配置方式和Spring相差不大，开发者在使用Dubbo的时候几乎没有太多的学习成本。基于XML形式的服务发布和服务消费的方式还是比较繁琐的，而且在发布的服务接口比较多的情况下，配置会非常复杂，所以Apache Dubbo也提供了对注解的支持，在接下来的案例中，笔者会简单演示基于Spring Boot集成Apache Dubbo来实现零配置的服务注册与发布。


## 4.3 Spring Boot集成Apache Dubbo

Apache Dubbo不需要依赖Spring Boot也是可以实现微服务的，集成到Spring Boot的好处是可以享受到Spring Boot生态的框架和技术支持，也就是**基于Spring Boot实现了标准化，并统一了开发、部署、运维的形态**。在2015年的时候，笔者所在公司就开始以Spring Boot集成Dubbo来实现微服务，不过，那时候整个生态没有现在这么成熟。现在，咱们可以使用Dubbo Spring Boot组件轻松集成，它整合了Spring Boot的自动装配、健康检查、外部化配置等功能。接下来通过一个案例来简单演示基于Spring Boot构建的Dubbo使用过程。

服务提供者开发流程
* 创建一个普通的Maven工程springboot-provider，并创建两个模块：sample-api和sample-provider，其中sample-provider模块是一个Spring Boot工程。
* 在sample-api模块中定义了一个接口，并通过mvn install安装到本地服务。
![](images/4.3.1.png)
* 在sample-provider中引入以下依赖，其中dubbo-spring-boot-starter是Apche Dubbo官方提供的开箱即用的组件。
![](images/4.3.2.png)
* 在sample-provider中实现IHelloService，并且使用Dubbo中提供的@Service注解发布服务。
![](images/4.3.3.png)
* 在application.properties文件中添加Dubbo服务的配置信息，配置元素在前面的章节中讲过，只是换了一种配置形式。
![](images/4.3.4.png)
* 启动Spring Boot，需要注意的是，需要在启动方法上添加@DubboComponentScan注解，它的作用和Spring Framework提供的@ComponetScan一样，只不过这里扫描的是Dubbo中提供的@Service注解。
![](images/4.3.5.png)


服务调用者的开发流程
服务调用者的开发流程相对来说也很简单。
* 创建一个Spring Boot项目spring-consumer，添加Jar包依赖。
![](images/4.3.6.png)
* 在application.properties中配置项目名称。
![](images/4.3.7.png)
* 在Spring Boot启动类中，使用Dubbo提供的@Reference注解来获得一个远程代理对象。
![](images/4.3.8.png)

相比基于XML的形式来说，**基于Dubbo-Spring-Boot-Starter组件来使用Dubbo完成服务发布和服务消费会使得开发更加简单**。另外，**官方还提供了Dubbo-Spring-Boot-Actuator模块，可以实现针对Dubbo服务的健康检查**；**还可以通过Endpoints实现Dubbo服务信息的查询和控制等，为生产环境中对Dubbo服务的监控提供了很好的支持**。

前面的两个案例中，主要还是使用Dubbo以点对点的形式来实现服务之间的通信，Dubbo可以很好地集成注册中心来实现服务地址的统一管理。**早期大部分公司采用的是ZooKeeper来实现注册**，接下来将带大家了解一下ZooKeeper，然后基于前面演示的案例整合ZooKeeper实现服务的注册和发现。


## 4.4 快速上手ZooKeeper

ZooKeeper**是一个高性能的分布式协调中间件**，所谓的分布式协调中间件的作用类似于多线程环境中通过并发工具包来协调线程的访问控制，只是分布式协调中间件主要解决分布式环境中各个服务进程的访问控制问题，比如访问顺序控制。所以，在这里需要强调的是，**ZooKeeper并不是注册中心，只是基于ZooKeeper本身的特性可以实现注册中心这个场景而已**。


### 4.4.1 ZooKeeper的安装
ZooKeeper的安装非常简单，需要注意的是，由于ZooKeeper是使用Java编写的，所以在安装之前必须要安装Java运行环境。另外，ZooKeeper支持单机部署和集群部署，由于本书并不是专门讲解ZooKeeper的，所以只会简单演示单机环境的安装过程，便于完成Dubbo和ZooKeeper的集成，安装步骤如下：
* 在Apache官网上下载ZooKeeper，笔者写作本书的时候最新版本为3.5.6。
* 将下载好的安装包解压到指定目录，解压后可以看到ZooKeeper包含很多目录，其中conf是存放配置文件的目录，bin是ZooKeeper提供的可执行脚本的目录。
* ${Zookeeper_Home}\conf目录下提供了ZooKeeper核心配置的样例文件zoo_sample.cfg，如果要将ZooKeeper运行起来，需要将其名称修改为zoo.cfg，内容可以暂时不用修改。
* 在${ZOOKEEPER_HOME}\bin路径下，执行sh zkServer.sh start，启动服务。
* 启动服务之后，就可以通过默认发布的2181端口来访问。如果在同一台机器上访问，通过sh zkCli.sh即可连接到ZooKeeper服务器。如果要连接到不同机器上的ZooKeeper服务，需要增加-server参数，即sh zkCli.sh-server target-server-ip：2181。


### 4.4.2 ZooKeeper的数据结构

![](images/4.4.2.1.png)
ZooKeeper的数据模型和分布式文件系统类似，**是一种层次化的属性结构**，如图4-2所示。和文件系统不同的是，**ZooKeeper的数据是结构化存储的，并没有在物理上体系出文件和目录**。

**ZooKeeper树中的每个节点被称为ZNode，Znode维护了一个stat状态信息，其中包含数据变化的时间和版本等**。并且每个Znode可以设置一个value值，**ZooKeeper并不用于通用的数据库或者大容量的对象存储，它只是关联和协调有关的数据**，所以value的数据大小不建议设置的非常大，较大的数据会带来更大的网络开销。

**ZooKeeper上的每个节点的数据都是允许读和写的，读表示获得指定Znode上的value数据，写表示修改指定Znode上的value数据**。另外，**节点的创建规则和文件系统中文件的创建规则类似，必须要按照层级创建**。举个简单的例子，如果需要创建/node/node1/node1-1，那么必须先创建/node/node1这两个层次节点。


### 4.4.3 ZooKeeper的特性

ZooKeeper中的Znode在被创建的时候，需要指定节点的类型，节点类型分为：
* 持久化节点，节点的数据会持久化到磁盘。
* 临时节点，节点的生命周期和创建该节点的客户端的生命周期保持一致，一旦该客户端的会话结束，则该客户端所创建的临时节点会被自动删除。
* 有序节点，在创建的节点后面会增加一个递增的序列，该序列在同一级父节点之下是唯一的。需要注意的是，持久化节点或者临时节点也是可以设置为有序节点的，也就是持久化有序节点或者临时有序节点。


 在3.5.3版本之后，又增加了两种节点类型，分别是：
* 容器节点，当容器节点下的最后一个子节点被删除时，容器节点就会被自动删除。
* TTL节点，针对持久化节点或者持久化有序节点，我们可以设置一个存活时间，如果在存活时间之内该节点没有任何修改并且没有任何子节点，它就会被自动删除。

需要注意的是，在同一层级目录下，节点的名称必须是唯一的，就像我们在同一个目录下不能创建两个有相同名字的文件夹一样。


### 4.4.4 Watcher机制

ZooKeeper提供了一种针对Znode的订阅/通知机制，**也就是当Znode节点状态发生变化时或者ZooKeeper客户端连接状态发生变化时，会触发事件通知**。**这个机制在服务注册与发现时，针对服务调用者及时感知到服务提供者的变化提供了非常好的解决方案**。
    
在ZooKeeper提供的Java API中，提供了三种机制来针对Znode进行注册监听，分别是：
* getData()，用于获取指定节点的value信息，并且可以注册监听，当监听的节点进行创建、修改、删除操作时，会触发相应的事件通知。
* getChildren()，用于获取指定节点的所有子节点，并且允许注册监听，当监听节点的子节点进行创建、修改、删除操作时，触发相应的事件通知。
* exists()，用于判断指定节点是否存在，同样可以注册针对指定节点的监听，监听的时间类型和getData()相同。

Watcher事件的触发都是一次性的，比如客户端通过getData（'/node',true）注册监听，如果/node节点发生数据修改，那么该客户端会收到一个修改事件通知，但是/node再次发生变化时，客户端无法收到Watcher事件，为了解决这个问题，客户端必须在收到的事件回调中再次注册事件。


### 4.4.5 常见应用场景分析

基于ZooKeeper中节点的特性，可以为多种应用场景提供解决方案。

分布式锁
用过多线程的读者应该都知道锁，比如Synchronized或者Lock，他们主要用于解决多线程环境下共享资源访问的数据安全性问题，但是他们所处理的范围是线程级别的。在分布式架构中，多线程对同一个共享资源的访问，也存在数据安全性问题，因此也需要使用锁的形式来解决这类问题，而解决分布式环境下对于共享资源的访问带来的安全性问题的方案就是使用分布式锁。锁的本质是排他性的，也就是避免在同一时刻多个进程同时访问某一个共享资源。

如果使用ZooKeeper实现分布式锁达到排他的目的，只需要用到节点的特性：临时节点，以及同级节点的唯一性。
* 获得锁的过程
在获得排他锁时，所有客户端可以去ZooKeeper服务器上/Exclusive_Locks节点下创建一个临时节点/lock。ZooKeeper基于同级节点的唯一性，会保证所有客户端中只有一个客户端能创建成功，创建成功的客户端获得了排他锁，没有获得锁的客户端就需要通过Watcher机制监听/Exclusive_Locks节点下子节点的变更事件，用于实时监听/lock节点的变化情况以做出反应。

* 释放锁的过程
在获得锁的过程中，我们定义的锁节点/lock为临时节点，那么在以下两种情况下会触发锁的释放。
    * 获得锁的客户端因为异常断开了和服务端的连接，基于临时节点的特性，/lock节点会被自动删除。
    * 获得锁的客户端执行完业务逻辑之后，主动删除了创建的/lock节点。
当/lock节点被删除之后，ZooKeeper服务器会通知所有监听了/Exclusive_Locks子节点变化的客户端。这些客户端收到通知后，再次发起创建/lock节点的操作来获得排他锁。


Master选举
Master选举是分布式系统中非常常见的场景，在分布式架构中，为了保证服务的可用性，通常会采用集群模式，也就是当其中一个机器宕机后，集群中的其他节点会接替节点继续工作。这种工作模式有点类似于公司中某些重要的A/B角，当A请假之后，B可以接替A继续工作。在这种场景中，就需要从集群中选举一个节点作为Master节点，剩下的节点都作为备份节点随时待命。当原有的Master节点出现故障之后，还需要从集群中的其他备份节点中选举一个节点作为Master节点继续提供服务。

ZooKeeper就可以帮助集群中的节点实现Master选举。具体而言，ZooKeeper中有两种方式来实现Master选举这一场景：
* **同一级节点不能重复创建一个已经存在的节点，这个有点类似于分布式锁的实现场景，其实Master选举的场景也是如此**。假设集群中有3个节点，需要选举出Master，那么这三个节点同时去ZooKeeper服务器上创建一个临时节点/master-election，由于节点的特性，只会有一个客户端创建成功，创建成功的客户端所在的集群就成了Master。同时，其他没有创建成功的客户端，针对该节点注册Warcher事件，用于监控当前的Master机器是否存活，一旦发现Master“挂了”，也就是/master-election节点被删除了，那么其他的客户端将会重新发起Master选举操作。
* **利用临时有序节点的特性来实现。所有参与选举的客户端在ZooKeeper服务器的/master节点下创建一个临时有序节点，编号最小的节点表示Master，后续的节点可以监听前一个节点的删除事件，用于触发重新选举，如图4-3所示，client01、client02、client03三个节点去ZooKeeper Service的/master节点下创建临时有序节点，编号最小的节点client01表示Master节点，client02和client03会分别通过Watcher集群监听比自己编号小的一个节点，比如client03会监听client01-0000000001节点的删除事件、client02会监听client-03-0000000002节点的删除事件，一旦最小的节点被删除，那么在图4-3这个场景中，client-03就会被选举为Master**。
![](images/4.4.5.1.png)


## 4.5 Apache Dubbo集成ZooKeeper实现服务注册

大规模服务化之后，在远程RPC通信过程中，会遇到两个比较尖锐的问题：
* 服务动态上下线感知。
* 负载均衡。

服务动态上下线感知，就是服务调用者要感知到服务提供者上下线的变化。按照以往传统的形式，服务调用者如果要调用服务提供者，必须要知道服务提供者的地址信息及映射参数。以Webservice为例，服务调用者需要在配置文件中维护一个http://ip:port/service?wsdl地址，但如果服务提供者是一个集群节点，那么服务调用者需要维护多个这样的地址。问题来了，一旦服务提供者的IP故障或者集群中某个节点下线了，服务调用者需要同步更新这些地址，但是这个操作如果人工来做是不现实的，所以**需要一个第三方软件来统一管理服务提供者的URL地址，服务调用者可以从这个软件中获得目标服务的相关地址，并且第三方软件需要动态感知服务提供者状态的变化来维护所管理的URL，进而使得服务调用者能够及时感知到变化而做出相应的处理**。
    
负载均衡这个概念大家都熟悉，就是当服务提供者是由多个节点组成的集群环境时，服务调用者需要通过负载均衡算法来动态选择一台目标服务器进行远程通信。**负载均衡的主要目的是通过多个节点的集群来均衡服务器的访问压力，提升整体性能**。实现负载均衡的前提是，要得到目标服务集群的所在地址，在服务调用者端进行计算，而地址的获取也同样依赖于第三方软件。

第三方软件的**主要功能其实就是服务注册和发现**，如图4-4所示，可以看到引入服务注册中心后服务调用者和服务提供者之间的访问变化。**Apache Dubbo支持多种注册中，比如ZooKeeper、Nacos、Redis等**。在开源版本中，**官方推荐使用的注册中心是ZooKeeper**，所以使用Apache Dubbo的公司大部分都用ZooKeeper来实现服务注册和发现，在本节中会简单介绍ZooKeeper，后续章节会详细分析Nacos。


### 4.5.1 Apache Dubbo集成ZooKeeper实现服务注册的步骤

由于Dubbo的关系，大家最早认识的ZooKeeper用于实现服务的注册和发现。在初步了解了ZooKeeper的特性之后，我们就可以将ZooKeeper集成进来实现Dubbo服务的注册和动态感知。还是以Spring boot集成Apache Dubbo的案例作为演示，完整代码请去笔者提供的GitHub地址下载。
    
在这个案例中，只需要非常简单的几个步骤就能完成服务注册的功能。
* 在springboot-provider项目的sample-provider模块中添加ZooKeeper相关依赖，其中curator-framework和curator-recipes是ZooKeeper的开源客户端。
![](images/4.5.1.1.png)

* 修改application.properties文件，修改dubbo.registry.address的地址为ZooKeeper服务器的地址，表示当前Dubbo服务需要注册到ZooKeeper上。
![](images/4.5.1.2.png)
* 服务调用方只需要修改application.properties，设置Dubbo服务注册中心的地址即可，当Dubbo调用方发起远程调用时，会去注册中心获取目标服务的URL地址以完成最终通信。
![](images/4.5.1.3.png)


### 4.5.2 ZooKeeper注册中心的实现原理

Dubbo服务注册到ZooKeeper上之后，可以在ZooKeeper服务器上看到如图4-5所示的树形结构。
![](images/4.5.2.1.png)
当Dubbo服务启动时，会去Zookeeper服务器上的/dubbo/com.gupaoedu.book.dubbo.IHellService/providers目录下创建当前服务的URL，其中com.gupanedu.book.dubbo.IHelloService是发布服务的接口的全路径名称，providers表示服务提供者的类型，dubbo://ip:port表示该服务发布的协议类型及访问地址。其中，URL是临时节点，其他皆为持久化节点。在这里使用临时节点的好处在于，如果注册该节点的服务器下线了，那么这个服务器的URL地址就会从ZooKeeper服务器上被移除。

**当Dubbo服务消费者启动时，会对/dubbo/com.gupaoedu.book.dubbo.IHelloService/providers节点下的子节点注册Watcher监听，这样便可以感知到服务提供方节点的上下线变化，从而防止请求发送到已经下线的服务器造成访问失败**。同时，**服务消费者会在dubbo/com.gupaoedu.book.dubbo.IHelloService/consumers下写入自己的URL，这样做的目的是可以在监控平台上看到某个Dubbo服务正在被哪些服务调用**。最重要的是，Dubbo服务的消费者如果需要调用IHelloService服务，那么它会先去/dubbo/com.gupaoedu.book.dubbo.IHelloService/providers路径下获得所有该服务的提供方URL列表，然后通过负载均衡算法计算出一个地址进行远程访问。

整体来看，**服务注册和动态感知的功能用到了ZooKeeper中的临时节点、持久化节点、Watcher等**，回过头看前面分析的ZooKeeper的应用场景可以发现，几乎所有的场景都是基于这些来完成的。另外，不得不提的是，**Dubbo还可以针对不同的情况来实现以下功能**。
* 基于临时节点的特性，当服务提供者宕机或者下线时，注册中心会自动删除该服务提供者的信息。
* 注册中心重启时，Dubbo能够自动恢复注册数据及订阅请求。
* 为了保证节点操作的安全性，ZooKeeper提供了ACL权限控制，在Dubbo中可以通过dubbo.registry.username/dubbo.registry.password设置节点的验证信息。
* 注册中心默认的根节点是/dubbo，如果需要针对不同环境设置不同的根节点，可以使用dubbo.registry.group修改跟节点名称。


## 4.6 实战Dubbo Spring Cloud














# [README](../README.md "回到 README")

